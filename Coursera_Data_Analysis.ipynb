{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a22057916w/Analysis-on-Online-Course-Data/blob/main/Coursera_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset\n",
        "Download the Coursera dataset from shared google drive by file id.\n"
      ],
      "metadata": {
        "id": "xuxElBC2e2yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 18oGZ87xBCx6YXjNRbytQe-dApQUSy3dR"
      ],
      "metadata": {
        "id": "_3dZjv-raO2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b6328c-9b96-413a-b3cf-8fcf969ae069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18oGZ87xBCx6YXjNRbytQe-dApQUSy3dR\n",
            "To: /content/CourseraDataset-Clean.csv\n",
            "\r  0% 0.00/5.41M [00:00<?, ?B/s]\r100% 5.41M/5.41M [00:00<00:00, 219MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "*   Removing duplicate courses (rows) based on \"Course Title\"\n",
        "*   Removing duplicate coruses (rows) base on \"Corrse Url\", keeping English \"Coruse Title\" only.\n",
        "*   Combing the keywords and performing one-hot encoding\n",
        "*   Performing one-hot encoding on \"Level\"\n",
        "  * 1->beginner\n",
        "  * 2->intermediate\n",
        "  * 3->not specified\n",
        "  * 4->advanced\n",
        "*   Performing one-hot encoding on \"Schedule\"\n",
        "  * 1->Flexible schedule\n",
        "  * 2->Hands-on learning\n",
        "\n"
      ],
      "metadata": {
        "id": "Dt87s3hS1Acg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-KanLue08Je"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"CourseraDataset-Clean.csv\")\n",
        "\n",
        "df['Keyword'] = pd.factorize(df['Keyword'])[0] + 1 # perform ordinal encoding\n",
        "df['Keyword'] = df['Keyword'].astype(str)\n",
        "df['Keyword'] = df.groupby('Course Title')['Keyword'].transform(', '.join) # combine keyword\n",
        "df = df.drop_duplicates(subset=[\"Course Title\"]) # remove duplicate rows based on \"Course Title\"\n",
        "\n",
        "# perform one-hot encoding on \"Keyword\"\n",
        "one_hot = df['Keyword'].str.get_dummies(sep=\", \")\n",
        "one_hot_keyword = one_hot[list(one_hot.columns)].apply(lambda x: ', '.join(x.dropna().astype(str)), axis=1)\n",
        "df['Keyword'] = one_hot_keyword\n",
        "\n",
        "# perform ordinal encoding on \"Level\"\n",
        "# 1->beginner; 2->intermediate; 3->advanced; 4>not specified;\n",
        "# custom_order = [\"Beginner level\", \"Indermediate level\", \"Advanced level\", \"not specified\"]\n",
        "custom_order = ['Beginner level', 'Intermediate level', 'Advanced level', 'Not specified']\n",
        "df['Level'] = OrdinalEncoder(categories=[custom_order], dtype=str).fit_transform(df[['Level']]) + 1    # Perform ordinal encoding\n",
        "\n",
        "# perform one-hot encoding on \"Schedule\"\n",
        "# 1->Flexible schedule; 2->Hands-on learning\n",
        "df['Schedule'] = pd.factorize(df['Schedule'])[0] + 1\n",
        "df['Schedule'] = df['Schedule'].astype(str)\n"
      ],
      "metadata": {
        "id": "BOfUQF2I1crS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the langdetect package to detect the language."
      ],
      "metadata": {
        "id": "fQfBflg9jM9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "MpabXs_sL1Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect\n",
        "\n",
        "# Function to detect the language of a string\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        language = detect(text)\n",
        "    except:\n",
        "        language = \"unknown\"\n",
        "    return language\n",
        "\n",
        "# Group by \"Course Url\" and filter duplicated courses to keep only English titles\n",
        "duplicates_grouped = df.groupby('Course Url').filter(lambda x: len(x) > 1)\n",
        "english_duplicates = duplicates_grouped[duplicates_grouped['Course Title'].apply(lambda x: detect_language(x) == 'en')]\n",
        "\n",
        "# Drop duplicated rows based on the \"Course Url\"\n",
        "cleaned_df = df.drop_duplicates(subset=['Course Url'], keep=False)\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "df = pd.concat([cleaned_df, english_duplicates])\n",
        "df"
      ],
      "metadata": {
        "id": "p7_YFht5jUqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jLFjCOF0sl7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"CourseraDataset-Preprocessed.csv\", index=False, encoding='utf-8-sig') # UTF-8 with BOM encoded"
      ],
      "metadata": {
        "id": "Ts_R9XEU1ktJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wAIUsRn6CrDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_df = pd.read_csv(\"CourseraDataset-Preprocessed.csv\", engine='python')\n",
        "preprocessed_df"
      ],
      "metadata": {
        "id": "-oY7ZjaA2Caa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}